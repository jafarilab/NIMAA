---
title: "NIMAA-vignette"
author: "Cheng Chen, Mohieddin Jafari"
date: "`r Sys.Date()`"
output: 
  rmarkdown::html_vignette:
    toc: true
    toc_depth: 3
vignette: >
  %\VignetteIndexEntry{NIMAA-vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```
## Introduction
Many numerical analyses are invalid when working with nominal data because the mode is the only way to measure central tendency for nominal data, and frequency testing, like Chi-square tests, is the most common statistical analysis that makes sense.
[NIMAA](https://github.com/jafarilab/NIMAA) package proposes a comprehensive set of pipeline to perform nominal data mining, which can effectively find label relationships of each nominal variable according to pairwise association with other nominal data.

It uses bipartite graphs to show how two different types of data are linked together, and it puts them in the incidence matrix to continue with network analysis. Finding large submatrices with non-missing values and edge prediction are other applications of NIMAA to explore local and global similarities within nominal variables.

Then, using a variety of different network projection methods, two unipartite graphs are constructed on the given submatrix. NIMAA provides several options for clustering projected networks and selecting the best one based on external prior knowledge. When weighted bipartite networks are considered, the best clustering results are used as the benchmark for imputation analysis. By using imputation analysis, we tried to get more information from the whole dataset even though there were some missing values. This benchmark is used to figure out which imputation method is the best. It looks at how similar the clustering results are before and after the imputations.
```{r setup}
library(NIMAA)
```
## 1 Exploring the data
In this section, we demonstrate how to do a NIMAA analysis on a weighted bipartite network using the `beatAML` dataset. `beatAML` is one of four datasets that can be found in the [NIMAA](https://github.com/jafarilab/NIMAA) package. This dataset has three columns: the first two contain nominal variables, while the third contains numerical variables.

```{r show data,echo=FALSE, results='asis'}
knitr::kable(NIMAA::beatAML[1:10,], caption='The first ten rows of beatAML dataset')
```
Read the data from the package:
```{r read the data}
# read the data
beatAML_data <- NIMAA::beatAML
```
### 1.1 Plotting the original data:
The `plotInput()` function prints some information about the incidence matrix derived from input data, such as its dimensions and the proportion of missing values, as well as the image of the matrix. It also returns the incidence matrix object.

NB: To keep the size of vignette small enough for CRAN rules, we won't output the interactive figure here.
```{r plotInput function,results='asis'}
beatAML_incidence_matrix <- plotInput(
  x = beatAML_data, # original data with 3 columns
  index_nominal = c(2,1), # the first two columns are nominal data
  index_numeric = 3,  # the third column is numeric data
  print_skim = FALSE, # if you want to check the skim output, set this as TRUE
  plot_weight = TRUE, # when plotting the weighted incidence matrix
  verbose = FALSE # NOT save the figures to local folder
  )
```

Na/missing values Proportion: 0.2603
```{r, echo=FALSE, out.width="100%", fig.cap="beatAML dataset as incidence matrix"}
knitr::include_graphics("patient_id-inhibitor.png")
```

### 1.2 Plotting the bipartite graph of the original data:
Given that we have the incidence matrix, we can easily reconstruct the corresponding bipartite network. In the [NIMAA](https://github.com/jafarilab/NIMAA) package, we have two options for visualizing the bipartite network: static or interactive plots.

#### 1.2.1 Static plot:
The `plotBipartite()` function customizes the corresponding bipartite network visualization based on the [igraph](https://igraph.org/r/) package and returns the igraph object.

```{r plotBipartite, fig.height = 7, fig.width = 7, fig.align = "center"}
bipartGraph <- plotBipartite(inc_mat = beatAML_incidence_matrix, vertex.label.display = T)

# show the igraph object
bipartGraph
```

#### 1.2.2 Interactive plot:
The `plotBipartiteInteractive()` function generates a customized interactive bipartite network visualization based on the [visNetwork](https://datastorm-open.github.io/visNetwork/)
package.

NB: To keep the size of vignette small enough, we do not output
the interactive figure here. Instead, we show a screenshot of part of the `beatAML` dataset.

```{r plotBipartiteInteractive, results='hide'}
plotBipartiteInteractive(inc_mat = beatAML_incidence_matrix)
```

```{r, echo=FALSE, out.width="100%", fig.cap="beatAML dataset as incidence matrix"}
knitr::include_graphics("interactiveplot.png")
```
### 1.3 Analysis of network properties
[NIMAA](https://github.com/jafarilab/NIMAA) package contains a function called `analyseNetwork` to provide more details about the network topology and common centrality measures for vertices and edges.

```{r}
analysis_reuslt <- analyseNetwork(bipartGraph)

# showing the general measures for network topology
analysis_reuslt$general_stats
```

## 2 Extracting large submatrices without missing values
In the case of a weighted bipartite graph, the dataset with the fewest missing values should be used for the next steps. This is to avoid the sensitivity problems of clustering-based methods. The `extractSubMatrix()` function extracts the submatrices that have non-missing values or have a certain percentage of missing values inside (not for elements-max matrix), depending on the argument's input. The result will also be shown as a [plotly](https://plotly.com/r/) plot, so you can see the screenshots of `beatAML` dataset below.

The extraction process is performed and visualized in two ways, which can be chosen depending on the user's preference: using the original input matrix (row-wise) and using the transposed matrix (column-wise). [NIMAA](https://github.com/jafarilab/NIMAA) extracts the largest submatrices with non-missing values or with a specified proportion of missing values (using the `bar` argument) in four ways predefined in the `shape` argument:

- **Square**, to extract square matrix with the equal number of rows and columns,
- **Rectangular_row**, to extract matrix with the maximum number of rows, 
- **Rectangular_col**, to extract matrix with the maximum number of columns,  
- **Rectangular_element_max**, to extract matrix with the maximum number of elements.

Here we extract two shapes of submatrix from the `beatAML_incidence_matrix` including square and rectangular, with the maximum number of elements:

```{r extractSubMatrix,eval=FALSE}
sub_matrices <- extractSubMatrix(
  x = beatAML_incidence_matrix,
  shape = c("Square", "Rectangular_element_max"), # the selected shapes of submatrices
  row.vars = "patient_id",
  col.vars = "inhibitor",
  plot_weight = TRUE
  )
```

```{r, echo=FALSE, out.width="30%", fig.cap="Row-wise arrangement"}
knitr::include_graphics("Row_wise_arrangement.png")
```
```{r, echo=FALSE, out.width="100%", fig.cap="Column-wise arrangement"}
knitr::include_graphics("Column_wise_arrangement.png")
```

A value called **binmatnest2.temperature** is also printed by this function that indicates the nestedness measure of the input matrix. If the input matrix is highly nested (`binmatnest2.temperature >= 1`), then splitting the input matrix into parts is recommended to follow the analysis in each part independently.

## 3 Cluster finding analysis of projected unipartite networks
The `findCluster()` function performs seven commonly used network clustering algorithms, optionally preprocessing the input incidence matrix and projecting the bipartite network into unipartite networks. Preprocessing options such as using normalization and defining a threshold help us remove edges that have low weights or are weak edges. Also, it is possible to continue using binarized or original edge weights before performing community detection or clustering. Finally, all of the clustering methods that were used can be compared and the best one chosen based on internal or external cluster validity measures such as average of silhouette width and Jaccard similarity index. Additionally to displaying in consul, the findings are provided as bar plots.

To begin, let us examine how to utilize `findCluster` to find clusters of `patient_id`s based on the `Rectangular_element_max` submatrix of the `beatAML` bipartite network projection to a patient's unipartite similarity network.

```{r, eval=FALSE, fig.height = 3, fig.width = 7, fig.align = "center"}
cls <- findCluster(
  sub_matrices$Rectangular_element_max,
  dim = 1,
  method = "all", # all available clustering methods
  normalization = TRUE, # normalize the input matrix
  rm_weak_edges = TRUE, # remove the weak edges in graph
  rm_method = 'delete', # delete the weak edges
  threshold = 'median', # Use median of edges' weights as threshold
  set_remaining_to_1 = TRUE, # set the weights of remaining edges to 1
  )

cls
```

Additionally, if external features (prior knowledge) are provided, the function compares the clustering results obtained with the external features in terms of similarity by setting `extra_feature` argument.

For instance, let's generate some random features for the patients in the `beatAML` dataset. The following is an example:

```{r generate extra features,eval=FALSE,echo=FALSE, results='asis'}
external_feature <- data.frame(row.names = cls$walktrap$names)
external_feature[,'membership'] <- paste('group',
                                         findCluster(sub_matrices$Rectangular_element_max,
                                                     method = c('walktrap'),
                                                     rm_weak_edges = T,
                                                     set_remaining_to_1 = F,
                                                     threshold = 'median',
                                                     comparison = F)$walktrap$membership)
dset1 <- utils::head(external_feature)
knitr::kable(dset1, format = "html")

```

Clustering is done on the patient similarity network again, but this time by setting the `extra_feature` argument to provide external validation for the cluster finding analysis.

```{r findcluster 1, eval=FALSE,fig.height = 6, fig.width = 7, fig.align = "center"}
cls <- findCluster(
  sub_matrices$Rectangular_element_max,
  dim = 1,
  method = "all", 
  normalization = TRUE, 
  rm_weak_edges = TRUE, 
  rm_method = 'delete', 
  threshold = 'median', 
  set_remaining_to_1 = TRUE, 
  extra_feature =external_feature # add a extra feature reference here!
  )

cls
```

As you can see, two new indices are included (`jaccard_similarity` and `corrected_rand`) as external cluster validity measures which represent the similarity between clustering and the prior knowledge used as ground truth.

The following sections show how to perform clustering analysis on the other part of the `beatAML` bipartite network, namely, `inhibitor`. In this case, we simply need to modify the `dim` to 2.

```{r,eval=FALSE,fig.height = 3, fig.width = 7, fig.align = "center"}
cls2 <- findCluster(
  sub_matrices$Rectangular_element_max, # the same submatrix
  dim = 2 # set to 2 to use the other part of bipartite network
  )

cls2
```

## 4 Explore the clusters
In this part we will do exploration about the result of clustering, mainly focus on the visualization of clusters.

### 4.1 plotCluster
`plotCluster()` will output an interactive network figure, in which nodes belonging to the same group will be given the same color, and nodes belonging to different groups will have different colors.
```{r plotcluster,eval = FALSE}
plotCluster(graph=cls2$graph,cluster = cls2$louvain)
```

```{r, eval=FALSE, echo=FALSE, out.width="100%", fig.cap="Interactive plot for function plotCluster()"}
knitr::include_graphics("plotCluster.png")
```


### 4.2 Visualize the clusters in sankey figure format
We use the sankey graph to represent the bipartite graph. The difference is that we group the nodes that belong to the same part and the same group in the two parts as 'summary' nodes, and output an interactive figure.
```{r visualClusterInBipartite,eval = FALSE}
visualClusterInBipartite(
  data = beatAML_data,
  community_left = cls$leading_eigen,
  community_right = cls2$fast_greedy,
  name_left = 'patient_id',
  name_right = 'inhibitor')
```

```{r, echo=FALSE, out.width="100%", fig.cap="Interactive plot for function visualClusterInBipartite()"}
knitr::include_graphics("visualClusterInBipartite.png")
```

### 4.3 Score clusters

When we get a cluster, we can score it, which mainly uses the [fpc](https://CRAN.R-project.org/package=fpc)  package, and secondly we will calculate the coverage, which is an indicator obtained from Almeida, Hélio, et al. "Is there a best quality metric for graph clusters?.", which is a clustering is given as the fraction of the weight of all intra-cluster edges with respect to the total weight of all edges in the whole graph.
```{r,eval=FALSE}
scoreCluster(community = cls2$infomap,
             graph = cls2$graph,
             distance_matrix = cls2$distance_matrix)
```

### 4.4 Validate clusters
`validateCluster()` will calculate the similarity of the given clustering result and the reference feature, that is, corrected.rand and jaccard_similarity
```{r,eval=FALSE}
validateCluster(dist_mat = cls$distance_matrix,
                extra_feature = external_feature,
                community = cls$leading_eigen)
```


## 5 Imputation

### 5.1 impute missing data
The `imputeMissingValue()` function can impute the missing values in the matrix, we only need to select which methods are needed. The result will be a list, each element is a matrix with no missing values.

it will perform a variety of numerical imputation according to the user's input, and return all the data that does not contain any missing data, a list of matrices. 

* 'median' will replace the missing values with the median of each rows(observations)

* 'knn' is the method in package \code{bnstruct}

* 'als' and 'svd' are methods from package \code{softImpute}

* 'CA', 'PCA' and 'FAMD' are from package \code{missMDA}

* others are from the famous \code{mice} package.

```{r}
imputations <- imputeMissingValue(
  inc_mat = beatAML_incidence_matrix,
  method = c('svd','median','als','CA')
  )
# show the result format
names(imputations)
```

### 5.2 Validate imputation
`validateImputation()` will calculate the 

1. Jaccard similarity

2. Dice similarity coefficient

3. Rand index

4. Minkowski (inversed)

5. Fowlkes–Mallows index

between each imputation and the reference community, then plot the ranking, user can find which imputation method is relatively better.
```{r, eval=FALSE, fig.height = 6, fig.width = 7, fig.align = "center"}
validation_of_imputation <- validateImputation(
  imputation = imputations,
  refer_community = cls$fast_greedy,
  clustering_args = cls$clustering_args
  )
```


## 6 Using the data with imputation to explore again

By the result from previous chapter, we can easily know that 'als' is the best method.

There is no missing value in imputation matrix
```{r,eval=FALSE}
NA %in% imputations$als
```

And the size of imputations are the same with original matrix.
```{r,eval=FALSE}
dim(imputations$als) == dim(beatAML_incidence_matrix)
```

Thus the users can use this imputation matrix as input matrix to re-do all the first 5 steps (no need to do extracting because this matrix is already without any missing value) to mining the relationships inside the original dataset.
